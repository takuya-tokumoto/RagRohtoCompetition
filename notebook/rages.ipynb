{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 参照\n",
    "    - [RAGコンペ参加記 (raggle)](https://qiita.com/ctc-j-ikai/items/9980f6a1c11ef444ba4d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ragas==0.1.14\n",
      "  Using cached ragas-0.1.14-py3-none-any.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (1.26.4)\n",
      "Collecting datasets (from ragas==0.1.14)\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tiktoken in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (0.8.0)\n",
      "Requirement already satisfied: langchain in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (0.2.12)\n",
      "Requirement already satisfied: langchain-core in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (0.2.29)\n",
      "Requirement already satisfied: langchain-community in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (0.2.11)\n",
      "Requirement already satisfied: langchain-openai in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (0.1.21)\n",
      "Requirement already satisfied: openai>1 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (1.58.1)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.1.14)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: nest-asyncio in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from ragas==0.1.14) (1.6.0)\n",
      "Collecting appdirs (from ragas==0.1.14)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (4.7.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (2.10.4)\n",
      "Requirement already satisfied: sniffio in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from openai>1->ragas==0.1.14) (4.12.2)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (3.16.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->ragas==0.1.14)\n",
      "  Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.1.14)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (2.32.3)\n",
      "Collecting xxhash (from datasets->ragas==0.1.14)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->ragas==0.1.14)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets->ragas==0.1.14)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (3.11.11)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (0.27.0)\n",
      "Requirement already satisfied: packaging in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from datasets->ragas==0.1.14) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langchain->ragas==0.1.14) (2.0.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langchain->ragas==0.1.14) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langchain->ragas==0.1.14) (0.1.147)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langchain->ragas==0.1.14) (8.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langchain-core->ragas==0.1.14) (1.33)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langchain-community->ragas==0.1.14) (0.6.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from tiktoken->ragas==0.1.14) (2024.11.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.14) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.14) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.14) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.14) (0.9.0)\n",
      "Requirement already satisfied: certifi in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.14) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.14) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.1.14) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas==0.1.14) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.1.14) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.1.14) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai>1->ragas==0.1.14) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas==0.1.14) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas==0.1.14) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.1.14) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.14) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.14) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.14) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.1.14) (1.17.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.14) (1.0.0)\n",
      "Using cached ragas-0.1.14-py3-none-any.whl (163 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Downloading pyarrow-18.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (40.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: appdirs, xxhash, pysbd, pyarrow, fsspec, dill, multiprocess, datasets, ragas\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.12.0\n",
      "    Uninstalling fsspec-2024.12.0:\n",
      "      Successfully uninstalled fsspec-2024.12.0\n",
      "Successfully installed appdirs-1.4.4 datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 pyarrow-18.1.0 pysbd-0.3.4 ragas-0.1.14 xxhash-3.5.0\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/ubuntu/miniconda3/envs/ragrohto/lib/python3.11/site-packages (1.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ragas==0.1.14\n",
    "!pip install nest-asyncio==1.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3862069693.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    from rag\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nest_asyncio\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# .envファイルを読み込む\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.environ.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.environ.get(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"rag-rohto\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# オフライン評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "\n",
    "def load_pdf_document(file_path: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"PDFドキュメントを読み込み、各ページのテキストを抽出\n",
    "\n",
    "    Args:\n",
    "        file_path (str): 読み込むPDFファイルのパス。\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, Any]]: 各ページのテキストとメタデータを含む辞書のリスト。\n",
    "            - \"content\" (str): ページから抽出されたテキスト内容。\n",
    "            - \"metadata\" (Dict[str, str]): メタデータ情報（以下を含む）:\n",
    "                - \"source\" (str): PDFファイルのパス。\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            documents.append({\"content\": page.extract_text(), \"metadata\": {\"source\": file_path}})\n",
    "\n",
    "    return documents\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    \"../dataset/Financial_Statements_2023.pdf\",\n",
    "    \"../dataset/Hada_Labo_Gokujun_Lotion_Overview.pdf\",\n",
    "    \"../dataset/Shibata_et_al_Research_Article.pdf\",\n",
    "    \"../dataset/V_Rohto_Premium_Product_Information.pdf\",\n",
    "    \"../dataset/Well-Being_Report_2024.pdf\",\n",
    "]\n",
    "\n",
    "\n",
    "def document_loader(file_paths: List[str], loader_func) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    複数のPDFファイルパスを受け取り、各ファイルから抽出されたドキュメントを\n",
    "    フラットなリストとして返す。\n",
    "\n",
    "    Args:\n",
    "        file_paths (List[str]): PDFファイルのパスリスト。\n",
    "        loader_func (Callable): 単一のPDFファイルを読み込む関数。\n",
    "\n",
    "    Returns:\n",
    "        List[Dict[str, str]]: 全ファイルのドキュメントをフラットなリストとして返す。\n",
    "    \"\"\"\n",
    "    # PDFファイルを読み込む\n",
    "    docs = [loader_func(file_path) for file_path in file_paths]\n",
    "    # リストをフラット化\n",
    "    all_documents = [item for sublist in docs for item in sublist]\n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import pdfplumber\n",
    "\n",
    "\n",
    "def load_pdf_document(file_path):\n",
    "    documents = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            documents.append({\"content\": page.extract_text(), \"metadata\": {\"source\": file_path}})\n",
    "    return documents\n",
    "\n",
    "\n",
    "file_paths = [\n",
    "    \"../dataset/Financial_Statements_2023.pdf\",\n",
    "    \"../dataset/Hada_Labo_Gokujun_Lotion_Overview.pdf\",\n",
    "    \"../dataset/Shibata_et_al_Research_Article.pdf\",\n",
    "    \"../dataset/V_Rohto_Premium_Product_Information.pdf\",\n",
    "    \"../dataset/Well-Being_Report_2024.pdf\",\n",
    "]\n",
    "\n",
    "# PDFファイルを読み込む\n",
    "docs = [load_pdf_document(file_path) for file_path in file_paths]\n",
    "# リストをフラット化\n",
    "docs_list = [item for sublist in docs for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1097, which is longer than the specified 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "514\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# `docs_list` を Document 型に変換\n",
    "docs_list_converted = [Document(page_content=doc[\"content\"], metadata=doc[\"metadata\"]) for doc in docs_list]\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "doc_splits = text_splitter.split_documents(docs_list_converted)\n",
    "print(len(doc_splits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_chroma import Chroma\n",
    "\n",
    "# db = Chroma.from_documents(doc_splits, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from sudachipy import dictionary\n",
    "from sudachipy import tokenizer\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "# 単語単位のn-gramを作成\n",
    "def generate_word_ngrams(text, i, j, binary=False):\n",
    "    tokenizer_obj = dictionary.Dictionary(dict=\"core\").create()\n",
    "    mode = tokenizer.Tokenizer.SplitMode.A\n",
    "    tokens = tokenizer_obj.tokenize(text, mode)\n",
    "    words = [token.surface() for token in tokens]\n",
    "\n",
    "    ngrams = []\n",
    "\n",
    "    for n in range(i, j + 1):\n",
    "        for k in range(len(words) - n + 1):\n",
    "            ngram = tuple(words[k : k + n])\n",
    "            ngrams.append(ngram)\n",
    "\n",
    "    if binary:\n",
    "        ngrams = list(set(ngrams))  # 重複を削除\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def preprocess_word_func(text: str) -> List[str]:\n",
    "    return generate_word_ngrams(text, 1, 1, True)\n",
    "\n",
    "\n",
    "# 文字単位のn-gramを作成\n",
    "def generate_character_ngrams(text, i, j, binary=False):\n",
    "    ngrams = []\n",
    "\n",
    "    for n in range(i, j + 1):\n",
    "        for k in range(len(text) - n + 1):\n",
    "            ngram = text[k : k + n]\n",
    "            ngrams.append(ngram)\n",
    "\n",
    "    if binary:\n",
    "        ngrams = list(set(ngrams))  # 重複を削除\n",
    "\n",
    "    return ngrams\n",
    "\n",
    "\n",
    "def preprocess_char_func(text: str) -> List[str]:\n",
    "    i, j = 1, 3\n",
    "    if len(text) < i:\n",
    "        return [text]\n",
    "    return generate_character_ngrams(text, i, j, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語と文字のBM25Retrieverを作成\n",
    "word_retriever = BM25Retriever.from_documents(doc_splits, preprocess_func=preprocess_word_func)\n",
    "char_retriever = BM25Retriever.from_documents(doc_splits, preprocess_func=preprocess_char_func)\n",
    "word_retriever.k = 4\n",
    "char_retriever.k = 4\n",
    "\n",
    "# EnsembleRetrieverを作成\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[word_retriever, char_retriever], weights=[0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len = 4\n",
      "metadata = {'source': '../dataset/Hada_Labo_Gokujun_Lotion_Overview.pdf'}\n",
      "本製品の容器には、環境に配慮したバイオマス原料を⼀部使⽤しています。\n",
      "＊：加⽔分解ヒアルロン酸（ナノ化ヒアルロン酸）、アセチルヒアルロン酸Na（スーパーヒアルロン酸）、乳酸球菌／ヒアルロン酸発\n",
      "酵液（乳酸発酵ヒアルロン酸）、ヒアルロン酸Na\n",
      "◆本品は、航空法で定める航空危険物に該当しません。\n",
      "★販売名：ハダラボモイスト化粧⽔d\n",
      "使⽤上の注意\n",
      "＜相談すること＞\n",
      "○肌に異常が⽣じていないかよく注意して使⽤すること。使⽤中、⼜は使⽤後⽇光にあたって、⾚み、はれ、か\n",
      "ゆみ、刺激、⾊抜け（⽩斑等）や⿊ずみ等の異常が現れた時は、使⽤を中⽌し、⽪フ科専⾨医等へ相談するこ\n",
      "と。そのまま使⽤を続けると症状が悪化することがある。\n",
      "＜その他使⽤上の注意＞\n",
      "○傷、はれもの、湿疹等、異常のある部位には使⽤しないこと。\n",
      "○⽬に⼊らないように注意し、⼊った時はすぐに⽔⼜はぬるま湯で洗い流すこと。なお、異常が残る場合は、眼\n",
      "科医に相談すること。\n",
      "肌ラボ 極潤ヒアルロン液に関連する製品\n",
      "当社は、お客様のウェブ体験の向上のため、アクセスを分析しコンテンツや広告をパーソナライズするためにクッキーを使⽤し Cookie 設定\n",
      "ます。詳細はプライバシーポリシーをご確認ください。プライバシーポリシー\n",
      "すべての Cookie を受け⼊れる\n",
      "https://jp.rohto.com/hadalabo/gokujun-lotion/ 1/2\n"
     ]
    }
   ],
   "source": [
    "query = \"肌ラボ 極潤ヒアルロン液の使用上の注意点を教えてください。\"\n",
    "\n",
    "context_docs = ensemble_retriever.invoke(query)\n",
    "print(f\"len = {len(context_docs)}\")\n",
    "\n",
    "first_doc = context_docs[0]\n",
    "print(f\"metadata = {first_doc.metadata}\")\n",
    "print(first_doc.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LCELを使ったRAGのChainの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    '''\\\n",
    "以下の文脈だけを踏まえて質問に回答してください。\n",
    "\n",
    "文脈: \"\"\"\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "質問: {question}\n",
    "'''\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "肌ラボ 極潤ヒアルロン液の使用上の注意点は以下の通りです：\n",
      "\n",
      "1. **肌の異常に注意**: 使用中または使用後に日光にあたって、赤み、はれ、かゆみ、刺激、色抜け（白斑等）や黒ずみ等の異常が現れた場合は、使用を中止し、皮膚科専門医等に相談すること。\n",
      "\n",
      "2. **異常のある部位には使用しない**: 傷、はれもの、湿疹等、異常のある部位には使用しないこと。\n",
      "\n",
      "3. **目に入らないように注意**: 目に入った場合はすぐに水またはぬるま湯で洗い流し、異常が残る場合は眼科医に相談すること。\n",
      "\n",
      "これらの注意点を守って使用することが推奨されています。\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = {\"context\": ensemble_retriever, \"question\": RunnablePassthrough()} | prompt | model | StrOutputParser()\n",
    "\n",
    "query = \"肌ラボ 極潤ヒアルロン液の使用上の注意点を教えてください。\"\n",
    "\n",
    "output = chain.invoke(query)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
